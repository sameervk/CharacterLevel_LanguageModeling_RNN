{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-level language modeling using LSTMs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Author: Sameer Kesava\n",
    "          * TensorFlow version: 2.0.0-alpha\n",
    "          * Training data: \"Tragedy of Hamlet\" https://www.gutenberg.org/cache/epub/1787/pg1787.txt\n",
    "          * 1 custom layer converting the input uint8 type data into one-hot float32 type categorical data\n",
    "          * 1 LSTM layer with 1024 units with Stateful = True \n",
    "          * 1 Dense layer with the number of units equal to the number of unique characters\n",
    "          * Number of time steps/Sequence Length: 100  \n",
    "          * Dropout: 0      \n",
    "          * Categorical Cross Entropy Loss function    \n",
    "          * Adam Optimizer(learning rate: .001)\n",
    "          * Batch size: 64\n",
    "          * Epochs: 100\n",
    "          * Categorical accuracy: 99.95%\n",
    "          * Prediction Function 1 uses tf.argmax for the next character\n",
    "          * Prediction Function 2 uses tf.random.categorical for the next character following the tensorflow \"Text Generation\" example\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the headers from the text file before reading it in\n",
    "with open('pg2265_noheader.txt', 'rt', encoding = 'utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162850"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Tragedie of Hamlet\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Number of unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', ' ', '!', '&', \"'\", '(', ')', ',', '-', '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = sorted(set(text))\n",
    "char_set[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(char_set)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '&': 3,\n",
       " \"'\": 4,\n",
       " '(': 5,\n",
       " ')': 6,\n",
       " ',': 7,\n",
       " '-': 8,\n",
       " '.': 9,\n",
       " '1': 10,\n",
       " ':': 11,\n",
       " ';': 12,\n",
       " '?': 13,\n",
       " 'A': 14,\n",
       " 'B': 15,\n",
       " 'C': 16,\n",
       " 'D': 17,\n",
       " 'E': 18,\n",
       " 'F': 19,\n",
       " 'G': 20,\n",
       " 'H': 21,\n",
       " 'I': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'V': 33,\n",
       " 'W': 34,\n",
       " 'Y': 35,\n",
       " 'Z': 36,\n",
       " '[': 37,\n",
       " ']': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2int = {ch:i for i, ch in enumerate(char_set)}\n",
    "char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '&', \"'\", '(', ')', ',', '-', '.', '1', ':', ';',\n",
       "       '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'Z', '[', ']',\n",
       "       'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
       "       'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or {i:ch for i, ch in enumerate(char_set)}\n",
    "# or int2char = dict(enumerate(char_set))\n",
    "# or simply this\n",
    "int2char_np = np.array(char_set)\n",
    "int2char_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the text to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_int = [char2int[x] for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162850"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating an array with dtype as uint8. If more than 256 characters, this needs to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_int = np.array(text_int, dtype = np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating X and Y data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of time steps for training\n",
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using tensorflow dataset class for fast processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n",
      "e\n",
      " \n",
      "T\n",
      "r\n",
      "a\n",
      "g\n",
      "e\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "text_int_tensor = tf.data.Dataset.from_tensor_slices(text_int)\n",
    "for i in text_int_tensor.take(10):\n",
    "    print(int2char_np[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenced_batch = text_int_tensor.batch(batch_size=seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The Tragedie of Hamlet\\n\\nActus Primus. Scoena Prima.\\n\\nEnter Barnardo and Francisco two Centinels.\\n\\n  B'\n",
      "\"arnardo. Who's there?\\n  Fran. Nay answer me: Stand & vnfold\\nyour selfe\\n\\n   Bar. Long liue the King\\n\\n \"\n"
     ]
    }
   ],
   "source": [
    "for i in sequenced_batch.take(2):\n",
    "    print(repr(''.join(int2char_np[i.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_Y_batches(batch):\n",
    "    input_data = batch[:-1]\n",
    "    target_data = batch[1:]\n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequenced_batch.map(X_Y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The Tragedie of Hamlet\\n\\nActus Primus. Scoena Prima.\\n\\nEnter Barnardo and Francisco two Centinels.\\n\\n  '\n",
      "'he Tragedie of Hamlet\\n\\nActus Primus. Scoena Prima.\\n\\nEnter Barnardo and Francisco two Centinels.\\n\\n  B'\n"
     ]
    }
   ],
   "source": [
    "for x_ts, y_ts in dataset.take(1):\n",
    "    print(repr(''.join(int2char_np[x_ts.numpy()])))\n",
    "    print(repr(''.join(int2char_np[y_ts.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed = 100)\n",
    "dataset = dataset.shuffle(buffer_size=10000).batch(batch_size = batch_size, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in dataset.take(-1):\n",
    "    count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "for ts_x,ts_y in dataset.take(-1):\n",
    "    train_x.append(ts_x.numpy())\n",
    "    train_y.append(ts_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 64, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorizing y data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_y = tf.reshape(train_y, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([160000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_y = tf.one_hot(cat_train_y, depth=num_classes, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([160000, 65])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_y = tf.reshape(cat_train_y, shape = [i for i in np.array(train_y).shape] + [65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25, 64, 100, 65])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cross-checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 12])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_int = np.random.randint(low = 0, high=25, size = (2,))\n",
    "rand_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": It harrowes me with fear & wonder\n",
      "  Barn. It would be spoke too\n",
      "\n",
      "   Mar. Question it Horatio\n",
      "\n",
      "   H\n"
     ]
    }
   ],
   "source": [
    "print(''.join(int2char_np[train_x[3,8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It harrowes me with fear & wonder\n",
      "  Barn. It would be spoke too\n",
      "\n",
      "   Mar. Question it Horatio\n",
      "\n",
      "   Ho\n"
     ]
    }
   ],
   "source": [
    "print(''.join(int2char_np[tf.argmax(cat_train_y[3,8], axis = 1).numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a layer to categorize the input data (can also use Lambda function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categorical_layer(tf.keras.layers.Layer):\n",
    "    \"\"\"Creating a layer to convert the input data into categorical data\"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super(categorical_layer, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "     \n",
    "    def call(self, input_):\n",
    "        return tf.one_hot(input_, depth=self.num_classes, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = tf.keras.Sequential([tf.keras.Input(shape=(seq_length,), batch_size=batch_size, dtype=np.uint8),\n",
    "                                 categorical_layer(num_classes=num_classes),\n",
    "                                 tf.keras.layers.Dense(units = 65, activation = None),                                  \n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 100, 65])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output =  test_model(train_x[0])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 100, 65])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train_y[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### End Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(batchsize = 64, lstm_units = 64, dropout = 0.5, stateful = True):\n",
    "    model = tf.keras.Sequential([tf.keras.Input(shape = (seq_length,), batch_size=batchsize, dtype = np.uint8),\n",
    "                                 categorical_layer(num_classes=num_classes),\n",
    "                             tf.keras.layers.LSTM(units = lstm_units, activation='tanh', return_sequences=True,\n",
    "                                                 stateful=stateful, dropout = dropout, recurrent_initializer = 'glorot_uniform'),\n",
    "                             tf.keras.layers.Dense(units=num_classes, activation=None)\n",
    "                                ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1_units = 1024\n",
    "dropout1 = 0\n",
    "stateful_ = True\n",
    "model =  model_fn(batch_size, lstm1_units, dropout1, stateful_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "categorical_layer_1 (categor (64, 100, 65)             0         \n",
      "_________________________________________________________________\n",
      "unified_lstm (UnifiedLSTM)   (64, 100, 1024)           4464640   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, 100, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 4,531,265\n",
      "Trainable params: 4,531,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss = loss, metrics = [tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoint_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(checkpoint_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback =  tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = train_x.shape[0]\n",
    "def data_generator(epochs):\n",
    "    \"\"\"Generator for yielding batches for model fitting\"\"\"\n",
    "    for i in range(epochs):\n",
    "        for i in range(batches):\n",
    "            yield train_x[i], cat_train_y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 63s 3s/step - loss: 3.3392 - categorical_accuracy: 0.1553\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 63s 3s/step - loss: 3.1277 - categorical_accuracy: 0.1755\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 3.0431 - categorical_accuracy: 0.1841\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 2.8255 - categorical_accuracy: 0.2401\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 65s 3s/step - loss: 2.5850 - categorical_accuracy: 0.3009\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 65s 3s/step - loss: 2.4413 - categorical_accuracy: 0.3280\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 65s 3s/step - loss: 2.3774 - categorical_accuracy: 0.3450\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 2.2743 - categorical_accuracy: 0.3657\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 2.2160 - categorical_accuracy: 0.3766\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 2.1641 - categorical_accuracy: 0.3857\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 2.1267 - categorical_accuracy: 0.3933\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 2.0815 - categorical_accuracy: 0.4037\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 2.0469 - categorical_accuracy: 0.4110\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 64s 3s/step - loss: 2.0153 - categorical_accuracy: 0.4197\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 65s 3s/step - loss: 1.9778 - categorical_accuracy: 0.4292\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 65s 3s/step - loss: 1.9427 - categorical_accuracy: 0.4385\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 65s 3s/step - loss: 1.9111 - categorical_accuracy: 0.4467\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 65s 3s/step - loss: 1.8775 - categorical_accuracy: 0.4554\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 65s 3s/step - loss: 1.8477 - categorical_accuracy: 0.4639\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.8163 - categorical_accuracy: 0.4718\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.7815 - categorical_accuracy: 0.4813\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.7484 - categorical_accuracy: 0.4897\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.7201 - categorical_accuracy: 0.4981\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.6925 - categorical_accuracy: 0.5056\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.6590 - categorical_accuracy: 0.5147\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.6230 - categorical_accuracy: 0.5249\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 1.5823 - categorical_accuracy: 0.5359\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.5435 - categorical_accuracy: 0.5458\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.5020 - categorical_accuracy: 0.5577\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.4671 - categorical_accuracy: 0.5683\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.4276 - categorical_accuracy: 0.5784\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.3910 - categorical_accuracy: 0.5890\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.3454 - categorical_accuracy: 0.6040\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.3004 - categorical_accuracy: 0.6168\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.2603 - categorical_accuracy: 0.6273\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.2268 - categorical_accuracy: 0.6371\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.1886 - categorical_accuracy: 0.6485\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.1324 - categorical_accuracy: 0.6651\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.0837 - categorical_accuracy: 0.6818\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 1.0393 - categorical_accuracy: 0.6952\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.9892 - categorical_accuracy: 0.7107\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.9436 - categorical_accuracy: 0.7250\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.9044 - categorical_accuracy: 0.7378\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.8614 - categorical_accuracy: 0.7501\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.8161 - categorical_accuracy: 0.7658\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.7752 - categorical_accuracy: 0.7786\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.7311 - categorical_accuracy: 0.7937\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.6881 - categorical_accuracy: 0.8069\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.6354 - categorical_accuracy: 0.8263\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.5911 - categorical_accuracy: 0.8403\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.5420 - categorical_accuracy: 0.8587\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.4921 - categorical_accuracy: 0.8757\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.4453 - categorical_accuracy: 0.8919\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.4084 - categorical_accuracy: 0.9049\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.3735 - categorical_accuracy: 0.9158\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.3382 - categorical_accuracy: 0.9272\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.3098 - categorical_accuracy: 0.9362\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.2796 - categorical_accuracy: 0.9453\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.2459 - categorical_accuracy: 0.9557\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.2166 - categorical_accuracy: 0.9640\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.1883 - categorical_accuracy: 0.9720\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.1679 - categorical_accuracy: 0.9762\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.1533 - categorical_accuracy: 0.9787\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.1380 - categorical_accuracy: 0.9818\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.1230 - categorical_accuracy: 0.9843\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.1113 - categorical_accuracy: 0.9863\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0991 - categorical_accuracy: 0.9879\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0888 - categorical_accuracy: 0.9892\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0803 - categorical_accuracy: 0.9903\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0724 - categorical_accuracy: 0.9914\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0645 - categorical_accuracy: 0.9922\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0579 - categorical_accuracy: 0.9928\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0512 - categorical_accuracy: 0.9936\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0462 - categorical_accuracy: 0.9941\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0410 - categorical_accuracy: 0.9948\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0366 - categorical_accuracy: 0.9952\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0326 - categorical_accuracy: 0.9956\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0288 - categorical_accuracy: 0.9961\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0259 - categorical_accuracy: 0.9965\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0235 - categorical_accuracy: 0.9969\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0215 - categorical_accuracy: 0.9973\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0197 - categorical_accuracy: 0.9976\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0181 - categorical_accuracy: 0.9979\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0168 - categorical_accuracy: 0.9981\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0155 - categorical_accuracy: 0.9983\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0144 - categorical_accuracy: 0.9986\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0135 - categorical_accuracy: 0.9988\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0126 - categorical_accuracy: 0.9990\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0119 - categorical_accuracy: 0.9991\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0112 - categorical_accuracy: 0.9992\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0107 - categorical_accuracy: 0.9994\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0103 - categorical_accuracy: 0.9995\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0099 - categorical_accuracy: 0.9995\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0095 - categorical_accuracy: 0.9995\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0091 - categorical_accuracy: 0.9996\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0087 - categorical_accuracy: 0.9997\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0086 - categorical_accuracy: 0.9997\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0084 - categorical_accuracy: 0.9997\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0090 - categorical_accuracy: 0.9997\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0099 - categorical_accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "initial_epoch = 0\n",
    "final_epoch = 100\n",
    "data_gen = data_generator(final_epoch-initial_epoch)\n",
    "history = model.fit_generator(data_gen, steps_per_epoch=batches, epochs=final_epoch, callbacks=[checkpoint_callback],\n",
    "                               shuffle=False, initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Prediction function 1 using tf.argmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_fn_1(input_text = 'ABC', text_len = 1000):\n",
    "    \"\"\"Batch size = 1\"\"\"\n",
    "    \n",
    "    # Checking if the input_text characters are in the character_set\n",
    "    for i in input_text:\n",
    "        if i not in char_set:\n",
    "            print('%s character not in the text' %i)\n",
    "            return    \n",
    "    \n",
    "    # Convert input text to numbers, encode and reshape\n",
    "    input_seq = [char2int[i] for i in input_text]\n",
    "    \n",
    "    \n",
    "    # Create new model and load_weights from the saved model\n",
    "    model = model_fn(batchsize=1, lstm_units=1024, dropout=0, stateful=True)\n",
    "    model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    model.build(input_shape=(1, None))\n",
    "    model.reset_states()\n",
    "    \n",
    "    generated_seq = tf.expand_dims(input_seq, axis = 0)\n",
    "    \n",
    "    for i in range(text_len):\n",
    "              \n",
    "        prediction = model(generated_seq)\n",
    "        \n",
    "        # Removing the batch dimension\n",
    "        prediction = tf.squeeze(prediction, axis = 0)\n",
    "        \n",
    "        prediction =  tf.argmax(prediction[-1]).numpy()\n",
    "        \n",
    "        generated_seq = tf.expand_dims([prediction], axis=0)\n",
    "        \n",
    "        input_seq.append(prediction)\n",
    "    \n",
    "    del model    \n",
    "    print('Output: \\n' + ''.join(int2char_np[input_seq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "Barn: This the chaple good:\n",
      "It ouchmest he dad beere the woold goofong this is Pouther,\n",
      "Cous ffrme, will man  am inder'd e heare,\n",
      "That Ile sot wnowe vsow mer Fayes bo he owee, And comle gines our State\n",
      "\n",
      "   Qu. Ohrech ase this such thous se thes what you will speake will geee your gooners serse,\n",
      "Now where the concruffor drawne heare fore,\n",
      "as he is heare and alloue vp the colsequonce:\n",
      "It wronco heare a beaterouere it selle in a brine of ity steeme,\n",
      "And it ar henching that this d and the will be the\n",
      "\n",
      "   Laer. Good God some Laty, this mad goed to Heauen,\n",
      "A blanke tham it wo at whis it feree ouchiss, and themer Possenoted\n",
      "\n",
      "   Qu. That the Scull cranse and make of you\n",
      "\n",
      "   Ham. Nor Hamlet of the Marthes, beaues.\n",
      "\n",
      "   Osh. I chall ob your portandesce.\n",
      "Whereis our Seauen,\n",
      "The Compustion crads haue kell mo Hor at thuse be anchellyoungge, Ofreaine.\n",
      "Oh that a Rogee and Sonder and Marneryes Mayes the Dengerous\n",
      "\n",
      "   Ham. How dong the Que net stand an  no, whe Loue of I at his heales:\n",
      "So fasie to pratere. H\n"
     ]
    }
   ],
   "source": [
    "pred_fn_1('Barn:', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction function 2 using tf.random.categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_fn_2(input_text = 'ABC', text_len = 1000, predict_factor = 1 ):\n",
    "    \"\"\"Batch size = 1\"\"\"\n",
    "    \n",
    "    # Checking if the input_text characters are in the character_set\n",
    "    for i in input_text:\n",
    "        if i not in char_set:\n",
    "            print('%s character not in the text' %i)\n",
    "            return    \n",
    "    \n",
    "    # Convert input text to numbers, encode and reshape\n",
    "    input_seq = [char2int[i] for i in input_text]\n",
    "    \n",
    "    \n",
    "    # Create new model and load_weights from the saved model\n",
    "    model = model_fn(batchsize=1, lstm_units=1024, dropout=0, stateful=True)\n",
    "    model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    model.build(tf.TensorShape([1,None]))\n",
    "    model.reset_states()\n",
    "    \n",
    "    generated_seq = tf.expand_dims(input_seq, axis = 0)\n",
    "    \n",
    "    # Predict_factor is for creating unpredictability in the prediction (from tensorflow text generation example)\n",
    "    # Higher it is, more interesting prediction\n",
    "    predict_factor = 1\n",
    "    \n",
    "    for i in range(text_len):\n",
    "                       \n",
    "        prediction = model(generated_seq)\n",
    "        \n",
    "        prediction = tf.squeeze(prediction, axis = 0)/predict_factor\n",
    "        \n",
    "        prediction =  tf.squeeze(tf.random.categorical(tf.expand_dims(prediction[-1]/1, axis=0), num_samples=1), axis=0).numpy()[0]\n",
    "        \n",
    "        generated_seq = tf.expand_dims([prediction], axis=0)\n",
    "        \n",
    "        input_seq.append(prediction)\n",
    "    \n",
    "    del model    \n",
    "    print('Output: \\n' + ''.join(int2char_np[input_seq]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "Barn: Nor mis Ser ione you tey no more dishate to keele:\n",
      "Sue not sengounncred man sercaitut vno my shele\n",
      "Hable Vortuen, whing thou distole Mo that Delmarknot This Courtelle?\n",
      "I hay dabe delieur the Surion, in I theate\n",
      "Of Hat are leat vnow some good yot seeme his is and to deere are all\n",
      "\n",
      "   goon. Haue you my so hanr that? a Maidy your Moriur\n",
      "\n",
      "   Ham. Haw chante for ot be ceafe\n",
      "\n",
      "   Ham. I me gles of him: that sane the seening  o leace times s\n",
      " on mer Sppasit shell seepenour lood,\n",
      "ie wath dese that Sealoue in the besore of his\n",
      "\n",
      "   Ham. You beane th s me Lore, he what no serucheane the Monne owne Mosters, in RenilTang.\n",
      "You muct amparring of hir Loue, addidda turth; and wielles it of thee,\n",
      "But in the with s ce\n",
      "s good Leed, whare as the negitious effells, the Pray remember mels\n",
      "\n",
      "   Ham. She porsue. There's a stlagge. This is the corsunere Ilaindeyot stowhal'd,\n",
      "At bucken their desioues, Spare. I houe the Ploeruly PlferFe\n",
      "Detisle then, Nathmar nownage in't,\n",
      "Trea't it plas'st must my Forder bakes a a\n"
     ]
    }
   ],
   "source": [
    "pred_fn_2('Barn:', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (condapy36)",
   "language": "python",
   "name": "condapy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
